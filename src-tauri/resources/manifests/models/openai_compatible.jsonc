{
  "$schema": "../../../../json_schema/model-schema.json",
  "id": "openai_compatible",
  "name": "OpenAI API Compatible (Koboldcpp, Llamacpp, etc.)",
  "description": "Integration with OpenAI compatible API",
  "type": "llm",
  "inference_type": ["chat", "completion"],
  "engine": "openai_compatible",
  "inference_fields": [
    "temperature",
    "top_p",
    "frequency_penalty",
    "presence_penalty",
    "top_k",
    "min_p",
    "top_a",
    "repetition_penalty",
    "smoothing_sampling",
    "xtc",
    "dry",
    "dynamic_temperature",
    "seed",
    "nsigma",
    "stop",
    "sampling_order",
    "reasoning"
  ],
  "fields": [
    {
      "key": "base_url",
      "label": "Base URL",
      "placeholder": "The base URL of the OpenAI compatible API",
      "required": true,
      "field_type": "url"
    },
    {
      "key": "api_key",
      "label": "API Key",
      "placeholder": "Your API key (if applicable)",
      "required": false,
      "field_type": "secret"
    },
    {
      "key": "model",
      "label": "Model",
      "placeholder": "The model to use (if applicable)",
      "required": false,
      "field_type": "string"
    }
  ]
}
